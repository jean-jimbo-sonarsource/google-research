{
  "cells": [
    {
      "metadata": {
        "id": "SY7vcrsHXgPv"
      },
      "cell_type": "code",
      "source": [
        "# Copyright 2022 Google LLC\n",
        "\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmt-QvUjmLQ2"
      },
      "outputs": [],
      "source": [
        "import dataclasses\n",
        "import os\n",
        "import tensorflow.compat.v1 as tf\n",
        "import itertools\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wL4RQkUzlY-u"
      },
      "outputs": [],
      "source": [
        "PROJECT_ROOT = '/your/project/folder/here'\n",
        "SUBDIR = 'your_subdir'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8WR9dqctjKW"
      },
      "outputs": [],
      "source": [
        "MODELS = [\n",
        "    'tgn',\n",
        "    'edgebank'\n",
        "]\n",
        "DATA = [\n",
        "    'tgbl_wiki;cc-subgraph;cc-subgraph;cc-subgraph',\n",
        "    'tgbl_coin;cc-subgraph;cc-subgraph;cc-subgraph',\n",
        "    'tgbl_review;cc-subgraph;cc-subgraph;cc-subgraph',\n",
        "    'tgbl_comment;cc-subgraph;cc-subgraph',\n",
        "    'tgbl_flight;AS;AS;AF',\n",
        "]\n",
        "EXPERIMENTS = [\n",
        "    'transductive',\n",
        "    'transfer_no_warmstart',\n",
        "    'transfer_warmstart',\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOcfnLo51XCU"
      },
      "outputs": [],
      "source": [
        "# Transform inputs.\n",
        "@dataclasses.dataclass(frozen=False)\n",
        "class DatasetSpec:\n",
        "  dataset: str = dataclasses.field(default_factory=str)\n",
        "  train_split: str = dataclasses.field(default_factory=str)\n",
        "  val_split: str = dataclasses.field(default_factory=str)\n",
        "  test_split: str = dataclasses.field(default_factory=str)\n",
        "\n",
        "@dataclasses.dataclass(frozen=False)\n",
        "class ExperimentResults:\n",
        "  experiment: str = dataclasses.field(default_factory=str)\n",
        "  train_results: dict[str, float] = dataclasses.field(default_factory=dict)\n",
        "  test_results: dict[str, float] = dataclasses.field(default_factory=dict)\n",
        "  val_warmstart_loss_metrics: pd.DataFrame = dataclasses.field(default_factory=pd.DataFrame)\n",
        "  val_loss_metrics: pd.DataFrame = dataclasses.field(default_factory=pd.DataFrame)\n",
        "  test_warmstart_loss_metrics: pd.DataFrame = dataclasses.field(default_factory=pd.DataFrame)\n",
        "  test_loss_metrics: pd.DataFrame = dataclasses.field(default_factory=pd.DataFrame)\n",
        "\n",
        "@dataclasses.dataclass(frozen=False)\n",
        "class ModelResults:\n",
        "  model: str = dataclasses.field(default_factory=str)\n",
        "  experiment_results: dict[str, ExperimentResults] = dataclasses.field(default_factory=dict)\n",
        "\n",
        "@dataclasses.dataclass(frozen=False)\n",
        "class DatasetResults:\n",
        "  dataset: str = dataclasses.field(default_factory=str)\n",
        "  model_results: dict[str, ModelResults] = dataclasses.field(default_factory=dict)\n",
        "\n",
        "DATASET_SPECS = []\n",
        "DATASETS = []\n",
        "for dataset_string in DATA:\n",
        "  dataset, train_split, val_split, test_split = dataset_string.split(';')\n",
        "  DATASETS.append(dataset)\n",
        "  DATASET_SPECS.append(DatasetSpec(dataset, train_split, val_split, test_split))\n",
        "\n",
        "RESULTS_SUBDIR = os.path.join(PROJECT_ROOT, 'experiments', SUBDIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jnhONMomItq"
      },
      "outputs": [],
      "source": [
        "ALL_RESULTS = {}\n",
        "train_results_df = pd.DataFrame(\n",
        "    index=pd.MultiIndex.from_product(\n",
        "        [MODELS, EXPERIMENTS],\n",
        "        names=['Model', 'Experiment']\n",
        "    ),\n",
        "    columns=pd.MultiIndex.from_product(\n",
        "        [DATASETS, ['auc', 'mrr']],\n",
        "        names=['Dataset', 'Metric']\n",
        "    )\n",
        ")\n",
        "test_results_df = pd.DataFrame(\n",
        "    index=pd.MultiIndex.from_product(\n",
        "        [MODELS, EXPERIMENTS],\n",
        "        names=['Model', 'Experiment']\n",
        "    ),\n",
        "    columns=pd.MultiIndex.from_product(\n",
        "        [DATASETS, ['auc', 'mrr']],\n",
        "        names=['Dataset', 'Metric']\n",
        "    )\n",
        ")\n",
        "for dataset_spec in DATASET_SPECS:\n",
        "  dataset_results = DatasetResults(dataset=dataset_spec.dataset)\n",
        "  for model in MODELS:\n",
        "    model_results = ModelResults(model=model)\n",
        "    model_dataset_folder = os.path.join(\n",
        "        RESULTS_SUBDIR,\n",
        "        dataset_spec.dataset, 'results',\n",
        "        f'{model}_{dataset_spec.dataset}_{dataset_spec.train_split}_{dataset_spec.val_split}'\n",
        "    )\n",
        "    for experiment in EXPERIMENTS:\n",
        "\n",
        "      # Extract results for train.\n",
        "      experiment_results = ExperimentResults(experiment=experiment)\n",
        "      with gfile.Open(os.path.join(model_dataset_folder, f'{experiment}_results_train.json'), 'r') as f:\n",
        "        experiment_results.train_results = json.load(f)\n",
        "      with gfile.Open(os.path.join(model_dataset_folder, f'{experiment}_val_loss.csv'), 'r') as f:\n",
        "        experiment_results.val_loss_metrics = pd.read_csv(f)\n",
        "      if not 'no_warmstart' in experiment:\n",
        "        with gfile.Open(os.path.join(model_dataset_folder, f'{experiment}_val_warmstart_loss.csv'), 'r') as f:\n",
        "          experiment_results.val_warmstart_loss_metrics = pd.read_csv(f)\n",
        "      train_results_df.loc[model, experiment].at[dataset_spec.dataset, 'auc'] = experiment_results.train_results['auc']\n",
        "      train_results_df.loc[model, experiment].at[dataset_spec.dataset, 'mrr'] = experiment_results.train_results['val mrr']\n",
        "\n",
        "      # Extract results for test.\n",
        "      # TODO: save test_split-specific results in their own subfolder of the train/val split folder.\n",
        "      with tf.io.gfile.open(os.path.join(model_dataset_folder, f'{experiment}_results_test_{dataset_spec.test_split}.json'), 'r') as f:\n",
        "        experiment_results.test_results = json.load(f)\n",
        "      with tf.io.gfile.open(os.path.join(model_dataset_folder, f'{experiment}_test_loss.csv'), 'r') as f:\n",
        "        experiment_results.test_loss_metrics = pd.read_csv(f)\n",
        "      if not 'no_warmstart' in experiment:\n",
        "        with tf.io.gfile.open(os.path.join(model_dataset_folder, f'{experiment}_test_warmstart_loss.csv'), 'r') as f:\n",
        "          experiment_results.test_warmstart_loss_metrics = pd.read_csv(f)\n",
        "      # TODO: align metric variable names across train and test.\n",
        "      test_results_df.loc[model, experiment].at[dataset_spec.dataset, 'auc'] = experiment_results.test_results['test auc']\n",
        "      test_results_df.loc[model, experiment].at[dataset_spec.dataset, 'mrr'] = experiment_results.test_results['test mrr']\n",
        "\n",
        "      model_results.experiment_results[experiment] = experiment_results\n",
        "\n",
        "    dataset_results.model_results[model] = model_results\n",
        "  ALL_RESULTS[dataset_spec.dataset] = dataset_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kbu84WAOOLZ0"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def plot_eval_metric_curves(\n",
        "    dataset='tgbl_wiki',\n",
        "    experiments=EXPERIMENTS,\n",
        "    model='tgn',\n",
        "    val=True,\n",
        "    metric_name='perf',\n",
        "    master_results_dict=ALL_RESULTS):\n",
        "\n",
        "  eval_df_string = 'val' if val else 'test'\n",
        "  plot_dataframes = []\n",
        "\n",
        "  # Make sure that if there is warmstart experiment that it comes first.\n",
        "  experiment_list = copy.deepcopy(experiments)\n",
        "  first_experiment = ''\n",
        "  for experiment in experiment_list:\n",
        "    if 'no_warmstart' not in experiment:\n",
        "      first_experiment = copy.deepcopy(experiment)\n",
        "  experiment_list.remove(first_experiment)\n",
        "  experiment_list = [first_experiment] + experiment_list\n",
        "\n",
        "  warmstart_end_index = 0\n",
        "  for idx, experiment in enumerate(experiment_list):\n",
        "    if 'no_warmstart' not in experiment:\n",
        "      warmstart_df = getattr(\n",
        "          master_results_dict[dataset].model_results[model].experiment_results[experiment],\n",
        "          f'{eval_df_string}_warmstart_loss_metrics'\n",
        "      )\n",
        "      if idx == 0:\n",
        "        warmstart_end_index = len(warmstart_df)\n",
        "      warmstart_df['batch_index'] = list(range(warmstart_end_index))\n",
        "      warmstart_df = warmstart_df.melt(\n",
        "          id_vars=['batch_index'],\n",
        "          value_vars=['loss', 'perf', 'auc'],\n",
        "          value_name='metric_value',\n",
        "          var_name='metric_name'\n",
        "      )\n",
        "      warmstart_df['experiment'] = experiment\n",
        "      warmstart_df = warmstart_df[warmstart_df.metric_name == metric_name]\n",
        "      warmstart_df['period'] = 'warmstart'\n",
        "      plot_dataframes.append(warmstart_df)\n",
        "\n",
        "\n",
        "    eval_df = getattr(\n",
        "        master_results_dict[dataset].model_results[model].experiment_results[experiment],\n",
        "        f'{eval_df_string}_loss_metrics'\n",
        "    )\n",
        "    eval_df['batch_index'] = list(range(warmstart_end_index, len(eval_df) + warmstart_end_index))\n",
        "    eval_df = eval_df.melt(\n",
        "        id_vars=['batch_index'],\n",
        "        value_vars=['loss', 'perf', 'auc'],\n",
        "        value_name='metric_value',\n",
        "        var_name='metric_name'\n",
        "    )\n",
        "    eval_df['experiment'] = experiment\n",
        "    eval_df = eval_df[eval_df.metric_name == metric_name]\n",
        "    eval_df['period'] = 'eval'\n",
        "    plot_dataframes.append(eval_df)\n",
        "\n",
        "  # Make plot.\n",
        "  master_plot_dataframe = pd.concat(plot_dataframes, axis=0)\n",
        "  plt.figure(figsize=(15, 10))\n",
        "  plt.title(f'{dataset} {eval_df_string} {model} {metric_name}')\n",
        "  sns.lineplot(\n",
        "      data=master_plot_dataframe,\n",
        "      x='batch_index',\n",
        "      y='metric_value',\n",
        "      hue='experiment',\n",
        "      style='period'\n",
        "  )\n",
        "  plt.show()\n",
        "  return master_plot_dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9uzcymifl8v"
      },
      "outputs": [],
      "source": [
        "plot_df = plot_eval_metric_curves(dataset='tgbl_wiki', val=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSoHNRh4dt6v"
      },
      "outputs": [],
      "source": [
        "plot_df = plot_eval_metric_curves(dataset='tgbl_wiki', val=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoM0Jsf0j94h"
      },
      "outputs": [],
      "source": [
        "plot_df = plot_eval_metric_curves(dataset='tgbl_review', val=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZHdRykIkEAq"
      },
      "outputs": [],
      "source": [
        "plot_df = plot_eval_metric_curves(dataset='tgbl_coin', val=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwaJNFhnJDJF"
      },
      "outputs": [],
      "source": [
        "plot_df = plot_eval_metric_curves(dataset='tgbl_coin', val=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "//learning/grp/tools/ml_python:ml_notebook",
        "kind": "private"
      },
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1LSHHrBHWDs-o_y68I_Lxv5fISoe15WFS",
          "timestamp": 1724442130455
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
